{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train\n",
      "(580, 750)\n",
      "(580,)\n",
      "\n",
      ">> test\n",
      "(562, 750)\n",
      "(562,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "save_path=\"D:\\\\study\\\\sugyeong_github\\\\FingerVein-Spoofing\\\\\"\n",
    "\n",
    "print('>> train')\n",
    "with open(save_path+\"train.pickle\", mode='rb') as f:\n",
    "    trainDict = pickle.load(f)\n",
    "\n",
    "train_X = trainDict['freq_signal']\n",
    "train_y = trainDict['class'].ravel()\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print()\n",
    "print('>> test')\n",
    "with open(save_path+\"test.pickle\", mode='rb') as f:\n",
    "    testDict = pickle.load(f)\n",
    "\n",
    "test_X = testDict['freq_signal']\n",
    "test_y = testDict['class'].ravel()\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv1D, MaxPooling1D, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "tmp = [[x,y] for x, y in zip(train_X,train_y)]\n",
    "random.shuffle(tmp)\n",
    "train_X = [n[0] for n in tmp]\n",
    "train_y = [n[1] for n in tmp]\n",
    "\n",
    "train_y=np.array(train_y)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data reshape & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 750, 1) (580,)\n"
     ]
    }
   ],
   "source": [
    "train_X=np.reshape(train_X, ( 580,750,1))\n",
    "test_X=np.reshape(test_X, ( 562,750,1))\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (580, 2)\n",
      "(562, 2)\n"
     ]
    }
   ],
   "source": [
    "train_y = to_categorical(train_y,2)\n",
    "test_y = to_categorical(test_y,2)\n",
    "print(type(train_y),train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[250:562])\n",
    "#print(test_y[0:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,val_X,train_y,val_y=train_test_split(train_X,train_y,test_size=0.4,shuffle=True,stratify=train_y,random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 374, 8)            32        \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 374, 8)            32        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 187, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 93, 16)            400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 93, 16)            64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 46, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 22, 32)            1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 22, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 22, 32)            1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 22, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 10, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 10, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 10, 64)            4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 10, 64)            256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                20512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 35,362\n",
      "Trainable params: 34,930\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "Train on 348 samples, validate on 232 samples\n",
      "Epoch 1/50\n",
      "338/348 [============================>.] - ETA: 0s - loss: 0.7078 - accuracy: 0.5858\n",
      "Epoch 00001: val_loss improved from inf to 0.73638, saving model to model.01-0.74.h5\n",
      "348/348 [==============================] - 4s 12ms/sample - loss: 0.7026 - accuracy: 0.5891 - val_loss: 0.7364 - val_accuracy: 0.4871\n",
      "Epoch 2/50\n",
      "344/348 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.7834\n",
      "Epoch 00002: val_loss improved from 0.73638 to 0.41384, saving model to model.02-0.41.h5\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.4491 - accuracy: 0.7859 - val_loss: 0.4138 - val_accuracy: 0.9052\n",
      "Epoch 3/50\n",
      "344/348 [============================>.] - ETA: 0s - loss: 0.4280 - accuracy: 0.8503\n",
      "Epoch 00003: val_loss did not improve from 0.41384\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.4239 - accuracy: 0.8520 - val_loss: 0.6690 - val_accuracy: 0.7414\n",
      "Epoch 4/50\n",
      "340/348 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.8824\n",
      "Epoch 00004: val_loss improved from 0.41384 to 0.19846, saving model to model.04-0.20.h5\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.2967 - accuracy: 0.8822 - val_loss: 0.1985 - val_accuracy: 0.9677\n",
      "Epoch 5/50\n",
      "336/348 [===========================>..] - ETA: 0s - loss: 0.2326 - accuracy: 0.9152\n",
      "Epoch 00005: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.2297 - accuracy: 0.9167 - val_loss: 0.9356 - val_accuracy: 0.8211\n",
      "Epoch 6/50\n",
      "343/348 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.9140\n",
      "Epoch 00006: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.1869 - accuracy: 0.9152 - val_loss: 1.8736 - val_accuracy: 0.5216\n",
      "Epoch 7/50\n",
      "346/348 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.8887\n",
      "Epoch 00007: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.2280 - accuracy: 0.8894 - val_loss: 2.1415 - val_accuracy: 0.5776\n",
      "Epoch 8/50\n",
      "339/348 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9543\n",
      "Epoch 00008: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.1495 - accuracy: 0.9555 - val_loss: 0.8110 - val_accuracy: 0.7759\n",
      "Epoch 9/50\n",
      "347/348 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9481\n",
      "Epoch 00009: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.1340 - accuracy: 0.9483 - val_loss: 1.6633 - val_accuracy: 0.8103\n",
      "Epoch 10/50\n",
      "347/348 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9352\n",
      "Epoch 00010: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.1435 - accuracy: 0.9353 - val_loss: 1.9132 - val_accuracy: 0.8147\n",
      "Epoch 11/50\n",
      "336/348 [===========================>..] - ETA: 0s - loss: 0.1837 - accuracy: 0.9375\n",
      "Epoch 00011: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.1787 - accuracy: 0.9397 - val_loss: 0.4702 - val_accuracy: 0.8793\n",
      "Epoch 12/50\n",
      "337/348 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9510\n",
      "Epoch 00012: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.1393 - accuracy: 0.9526 - val_loss: 3.2503 - val_accuracy: 0.5086\n",
      "Epoch 13/50\n",
      "345/348 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9681\n",
      "Epoch 00013: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.0974 - accuracy: 0.9684 - val_loss: 0.4926 - val_accuracy: 0.8491\n",
      "Epoch 14/50\n",
      "343/348 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9519\n",
      "Epoch 00014: val_loss did not improve from 0.19846\n",
      "348/348 [==============================] - 2s 5ms/sample - loss: 0.1576 - accuracy: 0.9497 - val_loss: 0.3962 - val_accuracy: 0.8922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230d115c4c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cnn():\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(activation='relu',input_shape=(750,1),strides=2,filters=8,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    \n",
    "    model.add(Conv1D(activation='relu',strides=2,filters=16,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    \n",
    "    model.add(Conv1D(activation='relu',strides=2,filters=32,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(activation='relu',strides=1,filters=32,kernel_size=1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv1D(activation='relu',strides=2,filters=64,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(activation='relu',strides=1,filters=64,kernel_size=1))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(MaxPooling1D(pool_size = 2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model\n",
    "model=cnn()\n",
    "model.summary()\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "]\n",
    "model.fit(train_X,train_y,epochs=50,callbacks=my_callbacks,verbose=1,batch_size=1,validation_data=(val_X,val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "562/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.8002 - accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss and Accuracy ->  [1.0542990295572698, 0.71352315]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.04-0.20_SGD.h5')\n",
    "\n",
    "performance_test = model.evaluate(test_X, test_y, batch_size=1)\n",
    "print('Test Loss and Accuracy -> ', performance_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능평가 결과\n",
    "- validation 0.4 로 했을때 model.06-0.16.h5\n",
    "    - loss & acc => 0.49 & 0.89\n",
    "- SGD로 했을때 model.04-0.20_SGD.h5\n",
    "    - 1.05 & 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.5166988e-06 9.9999988e-01]\n",
      " [1.0148901e-01 9.5175254e-01]\n",
      " [1.2446346e-06 1.0000000e+00]\n",
      " [1.3343046e-02 9.9756515e-01]\n",
      " [5.7274121e-04 9.9993801e-01]\n",
      " [1.0907582e-03 9.9983251e-01]\n",
      " [1.9844039e-03 9.9975520e-01]\n",
      " [9.9984384e-01 1.6689177e-05]\n",
      " [9.9480671e-01 1.8463597e-03]\n",
      " [2.8287157e-04 9.9997425e-01]\n",
      " [9.9119824e-01 3.8491113e-03]\n",
      " [4.5966062e-05 9.9999702e-01]\n",
      " [2.9248154e-02 9.9138016e-01]\n",
      " [2.3068315e-01 8.6303610e-01]\n",
      " [1.4719785e-03 9.9979132e-01]\n",
      " [5.5057731e-06 9.9999988e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [2.8240223e-07 1.0000000e+00]\n",
      " [6.1303942e-04 9.9992800e-01]\n",
      " [9.0250809e-04 9.9990261e-01]\n",
      " [7.7552795e-06 9.9999976e-01]\n",
      " [2.4267688e-06 9.9999988e-01]\n",
      " [7.8118426e-08 1.0000000e+00]\n",
      " [8.1564259e-08 1.0000000e+00]\n",
      " [4.7615645e-06 9.9999988e-01]\n",
      " [2.6856247e-05 9.9999869e-01]\n",
      " [9.0645878e-03 9.9824202e-01]\n",
      " [9.6986247e-03 9.9764758e-01]\n",
      " [1.0074449e-01 9.5912808e-01]\n",
      " [9.7225589e-01 1.2073341e-02]\n",
      " [7.8419000e-01 2.0631687e-01]\n",
      " [9.5776886e-01 1.3633308e-02]]\n",
      "============================\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(test_X,batch_size=1)\n",
    "print(result[530:])\n",
    "print(\"============================\")\n",
    "print(test_y[530:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29 samples, validate on 551 samples\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 1s 40ms/sample - loss: 0.6785 - accuracy: 0.9660 - val_loss: 0.6962 - val_accuracy: 0.4610\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 1s 25ms/sample - loss: 0.6431 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.4610\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 1s 24ms/sample - loss: 0.5984 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.4610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bc2cddb308>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nout):\n",
    "        super().__init__()\n",
    "\n",
    "        #self.add(layers.Dense(100, activation='relu', input_shape=(750,), name='Hidden-1'))\n",
    "        self.add(layers.Dense(50, activation='relu', name='Hidden-2'))\n",
    "        self.add(layers.Dense(Nout, activation='sigmoid'))\n",
    "        self.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#def main():\n",
    "number_of_class = 2\n",
    "Nout = number_of_class\n",
    "\n",
    "model = (DNN(Nout))\n",
    "    \n",
    "#history = model.fit(train_X, train_y, epochs=50, batch_size=16, validation_split=0.01)\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n",
    "]\n",
    "model.fit(train_X, train_y, epochs=10, callbacks=my_callbacks, batch_size = 1, validation_split=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "562/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 988us/sample - loss: 0.1594 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss and Accuracy ->  [0.15935717464766044, 1.0]\n"
     ]
    }
   ],
   "source": [
    "performance_test = model.evaluate(test_X, test_y, batch_size=1)\n",
    "print('Test Loss and Accuracy -> ', performance_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoofing",
   "language": "python",
   "name": "spoofing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
