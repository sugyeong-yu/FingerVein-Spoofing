{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train\n",
      "(580, 750)\n",
      "(580,)\n",
      "\n",
      ">> test\n",
      "(562, 750)\n",
      "(562,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "save_path=\"D:\\\\study\\\\sugyeong_github\\\\FingerVein-Spoofing\\\\\"\n",
    "\n",
    "print('>> train')\n",
    "with open(save_path+\"train.pickle\", mode='rb') as f:\n",
    "    trainDict = pickle.load(f)\n",
    "\n",
    "train_X = trainDict['freq_signal']\n",
    "train_y = trainDict['class'].ravel()\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print()\n",
    "print('>> test')\n",
    "with open(save_path+\"test.pickle\", mode='rb') as f:\n",
    "    testDict = pickle.load(f)\n",
    "\n",
    "test_X = testDict['freq_signal']\n",
    "test_y = testDict['class'].ravel()\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv1D, MaxPooling1D, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "tmp = [[x,y] for x, y in zip(train_X,train_y)]\n",
    "random.shuffle(tmp)\n",
    "train_X = [n[0] for n in tmp]\n",
    "train_y = [n[1] for n in tmp]\n",
    "\n",
    "train_y=np.array(train_y)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data reshape & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 750, 1) (580,)\n"
     ]
    }
   ],
   "source": [
    "train_X=np.reshape(train_X, ( 580,750,1))\n",
    "test_X=np.reshape(test_X, ( 562,750,1))\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (580, 2)\n",
      "(562, 2)\n"
     ]
    }
   ],
   "source": [
    "train_y = to_categorical(train_y,2)\n",
    "test_y = to_categorical(test_y,2)\n",
    "print(type(train_y),train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[250:562])\n",
    "#print(test_y[0:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,val_X,train_y,val_y=train_test_split(train_X,train_y,test_size=0.4,shuffle=True,stratify=train_y,random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 374, 8)            32        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 374, 8)            32        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 187, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 93, 16)            400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 93, 16)            64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 46, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 22, 32)            1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 22, 32)            1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 10, 64)            4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 64)            256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                20512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 35,362\n",
      "Trainable params: 34,930\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "Train on 348 samples, validate on 232 samples\n",
      "Epoch 1/50\n",
      "339/348 [============================>.] - ETA: 0s - loss: 0.7421 - accuracy: 0.5796\n",
      "Epoch 00001: val_loss improved from inf to 0.69282, saving model to model.01-0.69.h5\n",
      "348/348 [==============================] - 6s 16ms/sample - loss: 0.7367 - accuracy: 0.5819 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 2/50\n",
      "343/348 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8076\n",
      "Epoch 00002: val_loss did not improve from 0.69282\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.3803 - accuracy: 0.8075 - val_loss: 0.9569 - val_accuracy: 0.6056\n",
      "Epoch 3/50\n",
      "341/348 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9076\n",
      "Epoch 00003: val_loss improved from 0.69282 to 0.33371, saving model to model.03-0.33.h5\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.2235 - accuracy: 0.9037 - val_loss: 0.3337 - val_accuracy: 0.7823\n",
      "Epoch 4/50\n",
      "345/348 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9464\n",
      "Epoch 00004: val_loss did not improve from 0.33371\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.1878 - accuracy: 0.9468 - val_loss: 0.4084 - val_accuracy: 0.8944\n",
      "Epoch 5/50\n",
      "341/348 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9384\n",
      "Epoch 00005: val_loss did not improve from 0.33371\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.1769 - accuracy: 0.9382 - val_loss: 0.5057 - val_accuracy: 0.9095\n",
      "Epoch 6/50\n",
      "341/348 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9633\n",
      "Epoch 00006: val_loss improved from 0.33371 to 0.16294, saving model to model.06-0.16.h5\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.1308 - accuracy: 0.9641 - val_loss: 0.1629 - val_accuracy: 0.9591\n",
      "Epoch 7/50\n",
      "345/348 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 0.9768\n",
      "Epoch 00007: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.0895 - accuracy: 0.9770 - val_loss: 0.3135 - val_accuracy: 0.8685\n",
      "Epoch 8/50\n",
      "345/348 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9464\n",
      "Epoch 00008: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.1652 - accuracy: 0.9468 - val_loss: 6.2017 - val_accuracy: 0.4698\n",
      "Epoch 9/50\n",
      "342/348 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9810\n",
      "Epoch 00009: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.4586 - val_accuracy: 0.8707\n",
      "Epoch 10/50\n",
      "339/348 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9764\n",
      "Epoch 00010: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.0723 - accuracy: 0.9770 - val_loss: 0.6659 - val_accuracy: 0.7845\n",
      "Epoch 11/50\n",
      "340/348 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9941\n",
      "Epoch 00011: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.0259 - accuracy: 0.9943 - val_loss: 0.6297 - val_accuracy: 0.8341\n",
      "Epoch 12/50\n",
      "338/348 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9630\n",
      "Epoch 00012: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.2527 - accuracy: 0.9612 - val_loss: 0.4430 - val_accuracy: 0.9655\n",
      "Epoch 13/50\n",
      "338/348 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.9334\n",
      "Epoch 00013: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.2456 - accuracy: 0.9296 - val_loss: 0.5359 - val_accuracy: 0.9418\n",
      "Epoch 14/50\n",
      "343/348 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.9723\n",
      "Epoch 00014: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.1064 - accuracy: 0.9727 - val_loss: 9.0389 - val_accuracy: 0.5366\n",
      "Epoch 15/50\n",
      "343/348 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9767\n",
      "Epoch 00015: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.0535 - accuracy: 0.9770 - val_loss: 0.5139 - val_accuracy: 0.8427\n",
      "Epoch 16/50\n",
      "340/348 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9735\n",
      "Epoch 00016: val_loss did not improve from 0.16294\n",
      "348/348 [==============================] - 2s 6ms/sample - loss: 0.0885 - accuracy: 0.9741 - val_loss: 4.3585 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230744edd88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cnn():\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(activation='relu',input_shape=(750,1),strides=2,filters=8,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    \n",
    "    model.add(Conv1D(activation='relu',strides=2,filters=16,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    \n",
    "    model.add(Conv1D(activation='relu',strides=2,filters=32,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(activation='relu',strides=1,filters=32,kernel_size=1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv1D(activation='relu',strides=2,filters=64,kernel_size=3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(activation='relu',strides=1,filters=64,kernel_size=1))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(MaxPooling1D(pool_size = 2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model\n",
    "model=cnn()\n",
    "model.summary()\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "]\n",
    "model.fit(train_X,train_y,epochs=50,callbacks=my_callbacks,verbose=1,batch_size=1,validation_data=(val_X,val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "562/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 2.1102 - accuracy: 0.8932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss and Accuracy ->  [0.4904453895102772, 0.8932384]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.06-0.16.h5')\n",
    "\n",
    "performance_test = model.evaluate(test_X, test_y, batch_size=1)\n",
    "print('Test Loss and Accuracy -> ', performance_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능평가 결과\n",
    "- validation 0.4 로 했을때 model.06-0.16.h5\n",
    "    - loss & acc => 0.49 & 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.5166988e-06 9.9999988e-01]\n",
      " [1.0148901e-01 9.5175254e-01]\n",
      " [1.2446346e-06 1.0000000e+00]\n",
      " [1.3343046e-02 9.9756515e-01]\n",
      " [5.7274121e-04 9.9993801e-01]\n",
      " [1.0907582e-03 9.9983251e-01]\n",
      " [1.9844039e-03 9.9975520e-01]\n",
      " [9.9984384e-01 1.6689177e-05]\n",
      " [9.9480671e-01 1.8463597e-03]\n",
      " [2.8287157e-04 9.9997425e-01]\n",
      " [9.9119824e-01 3.8491113e-03]\n",
      " [4.5966062e-05 9.9999702e-01]\n",
      " [2.9248154e-02 9.9138016e-01]\n",
      " [2.3068315e-01 8.6303610e-01]\n",
      " [1.4719785e-03 9.9979132e-01]\n",
      " [5.5057731e-06 9.9999988e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [2.8240223e-07 1.0000000e+00]\n",
      " [6.1303942e-04 9.9992800e-01]\n",
      " [9.0250809e-04 9.9990261e-01]\n",
      " [7.7552795e-06 9.9999976e-01]\n",
      " [2.4267688e-06 9.9999988e-01]\n",
      " [7.8118426e-08 1.0000000e+00]\n",
      " [8.1564259e-08 1.0000000e+00]\n",
      " [4.7615645e-06 9.9999988e-01]\n",
      " [2.6856247e-05 9.9999869e-01]\n",
      " [9.0645878e-03 9.9824202e-01]\n",
      " [9.6986247e-03 9.9764758e-01]\n",
      " [1.0074449e-01 9.5912808e-01]\n",
      " [9.7225589e-01 1.2073341e-02]\n",
      " [7.8419000e-01 2.0631687e-01]\n",
      " [9.5776886e-01 1.3633308e-02]]\n",
      "============================\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(test_X,batch_size=1)\n",
    "print(result[530:])\n",
    "print(\"============================\")\n",
    "print(test_y[530:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29 samples, validate on 551 samples\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 1s 40ms/sample - loss: 0.6785 - accuracy: 0.9660 - val_loss: 0.6962 - val_accuracy: 0.4610\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 1s 25ms/sample - loss: 0.6431 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.4610\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 1s 24ms/sample - loss: 0.5984 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.4610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bc2cddb308>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nout):\n",
    "        super().__init__()\n",
    "\n",
    "        #self.add(layers.Dense(100, activation='relu', input_shape=(750,), name='Hidden-1'))\n",
    "        self.add(layers.Dense(50, activation='relu', name='Hidden-2'))\n",
    "        self.add(layers.Dense(Nout, activation='sigmoid'))\n",
    "        self.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#def main():\n",
    "number_of_class = 2\n",
    "Nout = number_of_class\n",
    "\n",
    "model = (DNN(Nout))\n",
    "    \n",
    "#history = model.fit(train_X, train_y, epochs=50, batch_size=16, validation_split=0.01)\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n",
    "]\n",
    "model.fit(train_X, train_y, epochs=10, callbacks=my_callbacks, batch_size = 1, validation_split=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "562/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 988us/sample - loss: 0.1594 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss and Accuracy ->  [0.15935717464766044, 1.0]\n"
     ]
    }
   ],
   "source": [
    "performance_test = model.evaluate(test_X, test_y, batch_size=1)\n",
    "print('Test Loss and Accuracy -> ', performance_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoofing",
   "language": "python",
   "name": "spoofing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
