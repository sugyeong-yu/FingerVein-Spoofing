{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.data[index], dtype=torch.float), torch.tensor(self.label[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        net = x\n",
    "        \n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "        \n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "        \n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        net = x\n",
    "        \n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "        \n",
    "        net = self.max_pool(net)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "                \n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "        \n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "            \n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "        \n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "        \n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "        \n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4,\n",
    "                 use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "                \n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "            \n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=self.kernel_size, \n",
    "                stride = self.stride, \n",
    "                groups = self.groups, \n",
    "                downsample=downsample, \n",
    "                use_bn = self.use_bn, \n",
    "                use_do = self.use_do, \n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x\n",
    "        \n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "        \n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        out = self.sigmoid(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "        \n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            print('terminating because of early stopping!')\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - min_delta\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + min_delta\n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|                                                                                    | 0/50 [00:00<?, ?it/s]\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train\n",
      ">> test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:10,  2.67it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.71it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:09,  2.72it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:09,  2.70it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.67it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.66it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:08,  2.71it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.71it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:07,  2.74it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:07,  2.67it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:04<00:06,  2.70it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:06,  2.66it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.67it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:05<00:05,  2.70it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:05,  2.66it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.69it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:06<00:04,  2.70it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:04,  2.69it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:07<00:03,  2.73it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:07<00:03,  2.75it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.75it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:08<00:02,  2.71it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:08<00:02,  2.70it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.68it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:09<00:01,  2.66it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:09<00:01,  2.67it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:10<00:00,  2.67it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:10<00:00,  2.71it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.72it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 13.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.5956611633300781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00,  9.32it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 10.03it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 11.24it/s]\u001b[A\n",
      "epoch:   2%|█▌                                                                          | 1/50 [00:11<09:23, 11.51s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6909346580505371, 0.6860474944114685, 0.6909346580505371, 0.6958217620849609, 0.6958217620849609, 0.6982653141021729, 0.6909346580505371, 0.6933781504631042]\n",
      "Loss/valid tensor(0.6928)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:11,  2.52it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:10,  2.61it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:09,  2.67it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:09,  2.71it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.69it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.76it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.78it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.78it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:07,  2.77it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.75it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:04<00:06,  2.77it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:06,  2.76it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.75it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:05<00:05,  2.78it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.80it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.76it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:06<00:04,  2.80it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.83it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.83it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:07<00:03,  2.79it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.83it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.85it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:08<00:02,  2.81it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.81it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:09<00:01,  2.77it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:09<00:01,  2.74it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.74it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:10<00:00,  2.76it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.77it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 14.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.41899800300598145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 14.37it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 14.51it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 15.76it/s]\u001b[A\n",
      "epoch:   4%|███                                                                         | 2/50 [00:22<08:58, 11.22s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7185467481613159, 0.7518206834793091, 0.7185735702514648, 0.6851633787155151, 0.6851637959480286, 0.6685677766799927, 0.7185118794441223, 0.701979398727417]\n",
      "Loss/valid tensor(0.7060)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:10,  2.74it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.80it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:09,  2.83it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.80it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.78it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.77it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.77it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.75it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:07,  2.78it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.78it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.73it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:06,  2.76it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.74it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:05<00:05,  2.69it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:05,  2.65it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.67it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:06<00:04,  2.75it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.80it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.82it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:07<00:03,  2.52it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:03,  2.51it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:08<00:02,  2.53it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:08<00:02,  2.61it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.67it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:09<00:01,  2.70it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:09<00:01,  2.66it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.74it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:10<00:00,  2.78it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.79it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 16.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.35152772068977356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 15.51it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 15.45it/s]\u001b[A\n",
      "epoch:   6%|████▌                                                                       | 3/50 [00:33<08:46, 11.19s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.560091495513916, 6.796024799346924, 5.559778690338135, 4.325285911560059, 4.324700832366943, 3.7069363594055176, 5.560047149658203, 4.948279857635498]\n",
      "Loss/valid tensor(5.0976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  2.82it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.80it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:09,  2.79it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.81it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.79it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.75it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.79it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.79it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:07,  2.84it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.85it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.89it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.87it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.84it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.85it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.84it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.84it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:07<00:03,  2.83it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.88it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.90it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:08<00:02,  2.92it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.90it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:08<00:01,  2.88it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:09<00:01,  2.85it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.87it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:09<00:00,  2.88it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.88it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 14.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.3134116232395172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 15.01it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 14.93it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 16.37it/s]\u001b[A\n",
      "epoch:   8%|██████                                                                      | 4/50 [00:44<08:25, 10.99s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.75, 31.25, 43.75, 56.25, 56.25, 62.5, 43.75, 50.0]\n",
      "Loss/valid tensor(48.4375)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  2.91it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.90it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:09,  2.87it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.90it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.86it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.82it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.85it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.88it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:06,  2.87it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.88it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.91it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.89it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.89it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.85it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.87it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.86it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.88it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:06<00:03,  2.90it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.92it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.93it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:07<00:02,  2.95it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.93it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:08<00:01,  2.89it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.88it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:09<00:00,  2.92it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.95it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 14.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.3293132185935974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 14.88it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 15.14it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 16.68it/s]\u001b[A\n",
      "epoch:  10%|███████▌                                                                    | 5/50 [00:54<08:07, 10.82s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.25, 68.75, 56.25, 43.75, 43.75, 37.5, 56.25, 50.0]\n",
      "Loss/valid tensor(51.5625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  2.83it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.92it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:08,  2.95it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.90it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.86it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.83it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.84it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.87it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.88it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  2.89it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.88it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.86it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.81it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.82it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.84it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.84it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.86it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:06<00:03,  2.86it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.83it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.85it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:08<00:02,  2.85it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.87it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:08<00:01,  2.88it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:09<00:01,  2.88it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.84it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:09<00:00,  2.84it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.86it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 15.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.31483685970306396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 15.33it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 15.70it/s]\u001b[A\n",
      "epoch:  12%|█████████                                                                   | 6/50 [01:05<07:53, 10.76s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.063267707824707, 9.856537818908691, 8.062272071838379, 6.2745161056518555, 6.271883010864258, 5.37587833404541, 8.06344223022461, 7.213059425354004]\n",
      "Loss/valid tensor(7.3976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  2.94it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.96it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:08,  2.91it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.88it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.90it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:08,  2.86it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.90it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.93it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.96it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.95it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  2.94it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.94it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.96it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.95it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.94it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.91it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.93it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.93it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:06<00:03,  2.93it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.92it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.90it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:07<00:02,  2.94it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.95it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:08<00:01,  2.96it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:08<00:01,  2.94it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.94it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:09<00:00,  2.94it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:09<00:00,  2.95it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 16.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.3097555637359619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 15.83it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 15.90it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 17.08it/s]\u001b[A\n",
      "epoch:  14%|██████████▋                                                                 | 7/50 [01:15<07:37, 10.64s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.75, 31.25, 43.75, 56.25, 56.25, 62.5, 43.75, 50.0]\n",
      "Loss/valid tensor(48.4375)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  3.00it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.98it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:08,  3.00it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  3.02it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.98it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:01<00:07,  3.01it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.96it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  3.00it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:02<00:06,  3.02it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  3.01it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.99it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  3.00it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.99it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.98it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.99it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.96it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.90it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:06<00:03,  2.93it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.93it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.96it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:07<00:02,  2.98it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.99it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:08<00:01,  3.01it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:08<00:01,  2.97it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.93it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:09<00:00,  2.94it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:09<00:00,  2.97it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 15.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.2992182970046997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 15.49it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 15.01it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 16.44it/s]\u001b[A\n",
      "epoch:  16%|████████████▏                                                               | 8/50 [01:26<07:22, 10.52s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.72782897949219, 24.800304412841797, 34.73115158081055, 44.6346435546875, 44.639381408691406, 49.60501480102539, 34.72307205200195, 39.68196105957031]\n",
      "Loss/valid tensor(38.4429)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  2.92it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.92it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:08,  2.92it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.98it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:07,  3.01it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:07,  2.97it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.90it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.92it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:06,  2.90it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.94it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  2.96it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.90it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.91it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.89it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.79it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.79it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.75it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:06<00:03,  2.80it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.80it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.82it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:08<00:02,  2.62it/s]\u001b[A\n",
      "Training:  83%|███████████████████████████████████████████████████████████▌            | 24/29 [00:08<00:01,  2.70it/s]\u001b[A\n",
      "Training:  86%|██████████████████████████████████████████████████████████████          | 25/29 [00:08<00:01,  2.73it/s]\u001b[A\n",
      "Training:  90%|████████████████████████████████████████████████████████████████▌       | 26/29 [00:09<00:01,  2.73it/s]\u001b[A\n",
      "Training:  93%|███████████████████████████████████████████████████████████████████     | 27/29 [00:09<00:00,  2.77it/s]\u001b[A\n",
      "Training:  97%|█████████████████████████████████████████████████████████████████████▌  | 28/29 [00:09<00:00,  2.80it/s]\u001b[A\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.82it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Validation:   0%|                                                                                | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Validation:  25%|██████████████████                                                      | 2/8 [00:00<00:00, 15.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.2945273816585541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  50%|████████████████████████████████████                                    | 4/8 [00:00<00:00, 16.37it/s]\u001b[A\n",
      "Validation:  75%|██████████████████████████████████████████████████████                  | 6/8 [00:00<00:00, 16.10it/s]\u001b[A\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 16.63it/s]\u001b[A\n",
      "epoch:  18%|█████████████▋                                                              | 9/50 [01:36<07:13, 10.58s/it]\u001b[A\n",
      "Training:   0%|                                                                                 | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48.49751281738281, 59.27677917480469, 48.4961051940918, 37.72462463378906, 37.72098159790039, 32.332252502441406, 48.497779846191406, 43.141204833984375]\n",
      "Loss/valid tensor(44.4609)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|██▌                                                                      | 1/29 [00:00<00:09,  2.88it/s]\u001b[A\n",
      "Training:   7%|█████                                                                    | 2/29 [00:00<00:09,  2.90it/s]\u001b[A\n",
      "Training:  10%|███████▌                                                                 | 3/29 [00:01<00:08,  2.93it/s]\u001b[A\n",
      "Training:  14%|██████████                                                               | 4/29 [00:01<00:08,  2.90it/s]\u001b[A\n",
      "Training:  17%|████████████▌                                                            | 5/29 [00:01<00:08,  2.93it/s]\u001b[A\n",
      "Training:  21%|███████████████                                                          | 6/29 [00:02<00:07,  2.90it/s]\u001b[A\n",
      "Training:  24%|█████████████████▌                                                       | 7/29 [00:02<00:07,  2.86it/s]\u001b[A\n",
      "Training:  28%|████████████████████▏                                                    | 8/29 [00:02<00:07,  2.87it/s]\u001b[A\n",
      "Training:  31%|██████████████████████▋                                                  | 9/29 [00:03<00:06,  2.87it/s]\u001b[A\n",
      "Training:  34%|████████████████████████▊                                               | 10/29 [00:03<00:06,  2.85it/s]\u001b[A\n",
      "Training:  38%|███████████████████████████▎                                            | 11/29 [00:03<00:06,  2.89it/s]\u001b[A\n",
      "Training:  41%|█████████████████████████████▊                                          | 12/29 [00:04<00:05,  2.90it/s]\u001b[A\n",
      "Training:  45%|████████████████████████████████▎                                       | 13/29 [00:04<00:05,  2.88it/s]\u001b[A\n",
      "Training:  48%|██████████████████████████████████▊                                     | 14/29 [00:04<00:05,  2.82it/s]\u001b[A\n",
      "Training:  52%|█████████████████████████████████████▏                                  | 15/29 [00:05<00:04,  2.87it/s]\u001b[A\n",
      "Training:  55%|███████████████████████████████████████▋                                | 16/29 [00:05<00:04,  2.83it/s]\u001b[A\n",
      "Training:  59%|██████████████████████████████████████████▏                             | 17/29 [00:05<00:04,  2.82it/s]\u001b[A\n",
      "Training:  62%|████████████████████████████████████████████▋                           | 18/29 [00:06<00:03,  2.84it/s]\u001b[A\n",
      "Training:  66%|███████████████████████████████████████████████▏                        | 19/29 [00:06<00:03,  2.87it/s]\u001b[A\n",
      "Training:  69%|█████████████████████████████████████████████████▋                      | 20/29 [00:06<00:03,  2.92it/s]\u001b[A\n",
      "Training:  72%|████████████████████████████████████████████████████▏                   | 21/29 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Training:  76%|██████████████████████████████████████████████████████▌                 | 22/29 [00:07<00:02,  2.89it/s]\u001b[A\n",
      "Training:  79%|█████████████████████████████████████████████████████████               | 23/29 [00:07<00:02,  2.89it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-ee87bca453d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mbase_filters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_filters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mfilter_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         m_blocks_list=m_blocks_list)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-ee87bca453d9>\u001b[0m in \u001b[0;36mrun_exp\u001b[1;34m(base_filters, filter_list, m_blocks_list)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "def run_exp(base_filters, filter_list, m_blocks_list):\n",
    "\n",
    "    dataset = MyDataset(X_train, Y_train) # Dataloader\n",
    "    dataset,dataset_val = random_split(dataset,[int(len(X_train)*0.8),len(X_train)-int(len(X_train)*0.8)])\n",
    "    dataset_test = MyDataset(X_test, Y_test)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=batch_size, drop_last=False)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, drop_last=False)\n",
    "    \n",
    "    # make model\n",
    "    device_str = \"cuda\"\n",
    "    device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kernel_size = 1\n",
    "    stride = 2\n",
    "    n_block = 48\n",
    "    downsample_gap = 6\n",
    "    increasefilter_gap = 12\n",
    "    \n",
    "    model = ResNet1D(\n",
    "        in_channels=1, \n",
    "        base_filters=base_filters, # 64 for ResNet1D, 352 for ResNeXt1D\n",
    "        kernel_size=kernel_size, \n",
    "        stride=stride, \n",
    "        groups=32, \n",
    "        n_block=n_block, \n",
    "        n_classes=2, \n",
    "        downsample_gap=downsample_gap, \n",
    "        increasefilter_gap=increasefilter_gap, \n",
    "        use_do=True)\n",
    "    model.to(device)\n",
    "\n",
    "    #summary(model, (X_train.shape[1], X_train.shape[2]), device=device_str)\n",
    "\n",
    "    # train and test\n",
    "    loss_function=torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    n_epoch = 50\n",
    "    step = 0\n",
    "    for _ in tqdm(range(n_epoch), desc=\"epoch\", leave=False):\n",
    "\n",
    "        # =============================================train====================================================\n",
    "        model.train()\n",
    "        prog_iter = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "        train_loss=[]\n",
    "        for batch_idx, batch in enumerate(prog_iter):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "            pred = model(input_x)\n",
    "            pred=pred.type(torch.FloatTensor)\n",
    "            input_y=input_y.type(torch.FloatTensor)\n",
    "            \n",
    "            loss = loss_function(pred,input_y)#F.binary_cross_entropy(pred, input_y)\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step() # 매개변수 갱신\n",
    "            step += 1\n",
    "        \n",
    "        loss=torch.mean(torch.tensor(train_loss))\n",
    "        writer.add_scalar('Loss/train', loss.item(), step)\n",
    "        print('Loss/train', loss.item())\n",
    "#             if is_debug:\n",
    "#                 break\n",
    "                    \n",
    "        # val\n",
    "        model.eval()\n",
    "        prog_iter_val = tqdm(dataloader_val, desc=\"Validation\", leave=False)\n",
    "        val_step=0\n",
    "        with torch.no_grad():\n",
    "            val_loss=[]\n",
    "            for batch_idx, batch in enumerate(prog_iter_val):\n",
    "                input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "                pred = model(input_x)\n",
    "                pred=pred.type(torch.FloatTensor)\n",
    "                input_y=input_y.type(torch.FloatTensor)\n",
    "                valid_loss = loss_function(pred,input_y)#F.binary_cross_entropy(pred, input_y)\n",
    "                val_loss.append(valid_loss.item())\n",
    "                val_step+=1\n",
    "                writer.add_scalar('Loss/valid', valid_loss.item(), val_step)\n",
    "            print(val_loss)\n",
    "            loss=torch.mean(torch.tensor(val_loss))\n",
    "            print('Loss/valid',loss)\n",
    "            \n",
    "            scheduler.step(valid_loss) # lr 조정\n",
    "            es=EarlyStopping(patience=10)\n",
    "            if es.step(loss):\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "                \n",
    "#                 all_pred_prob.append(pred.cpu().data.numpy())\n",
    "#         all_pred_prob = np.concatenate(all_pred_prob)\n",
    "#         all_pred = np.argmax(all_pred_prob, axis=1)\n",
    "#         ## vote most common\n",
    "#         final_pred = []\n",
    "#         final_gt = []\n",
    "#         for i_pid in np.unique(pid_val):\n",
    "#             tmp_pred = all_pred[pid_val==i_pid]\n",
    "#             tmp_gt = Y_val[pid_val==i_pid]\n",
    "#             final_pred.append(Counter(tmp_pred).most_common(1)[0][0])\n",
    "#             final_gt.append(Counter(tmp_gt).most_common(1)[0][0])\n",
    "#         ## classification report\n",
    "#         tmp_report = classification_report(final_gt, final_pred, output_dict=True)\n",
    "#         print(confusion_matrix(final_gt, final_pred))\n",
    "#         f1_score = (tmp_report['0']['f1-score'] + tmp_report['1']['f1-score'] + tmp_report['2']['f1-score'] + tmp_report['3']['f1-score'])/4\n",
    "# #         writer.add_scalar('F1/f1_score', f1_score, _)\n",
    "# #         writer.add_scalar('F1/label_0', tmp_report['0']['f1-score'], _)\n",
    "# #         writer.add_scalar('F1/label_1', tmp_report['1']['f1-score'], _)\n",
    "# #         writer.add_scalar('F1/label_2', tmp_report['2']['f1-score'], _)\n",
    "# #         writer.add_scalar('F1/label_3', tmp_report['3']['f1-score'], _)\n",
    "                    \n",
    "#         # test\n",
    "#         model.eval()\n",
    "#         prog_iter_test = tqdm(dataloader_test, desc=\"Testing\", leave=False)\n",
    "#         all_pred_prob = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch_idx, batch in enumerate(prog_iter_test):\n",
    "#                 input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "#                 pred = model(input_x)\n",
    "#                 all_pred_prob.append(pred.cpu().data.numpy())\n",
    "#         all_pred_prob = np.concatenate(all_pred_prob)\n",
    "#         all_pred = np.argmax(all_pred_prob, axis=1)\n",
    "#         ## vote most common\n",
    "#         final_pred = []\n",
    "#         final_gt = []\n",
    "#         for i_pid in np.unique(pid_test):\n",
    "#             tmp_pred = all_pred[pid_test==i_pid]\n",
    "#             tmp_gt = Y_test[pid_test==i_pid]\n",
    "#             final_pred.append(Counter(tmp_pred).most_common(1)[0][0])\n",
    "#             final_gt.append(Counter(tmp_gt).most_common(1)[0][0])\n",
    "#         ## classification report\n",
    "#         tmp_report = classification_report(final_gt, final_pred, output_dict=True)\n",
    "#         print(confusion_matrix(final_gt, final_pred))\n",
    "#         f1_score = (tmp_report['0']['f1-score'] + tmp_report['1']['f1-score'] + tmp_report['2']['f1-score'] + tmp_report['3']['f1-score'])/4\n",
    "# #         writer.add_scalar('F1/f1_score', f1_score, _)\n",
    "# #         writer.add_scalar('F1/label_0', tmp_report['0']['f1-score'], _)\n",
    "# #         writer.add_scalar('F1/label_1', tmp_report['1']['f1-score'], _)\n",
    "# #         writer.add_scalar('F1/label_2', tmp_report['2']['f1-score'], _)\n",
    "# #         writer.add_scalar('F1/label_3', tmp_report['3']['f1-score'], _)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    is_debug = False\n",
    "    if is_debug:\n",
    "        writer = SummaryWriter('D:\\\\study\\\\sugyeong_github\\\\FingerVein-Spoofing\\\\model\\\\debug')\n",
    "    else:\n",
    "        writer = SummaryWriter('D:\\\\study\\\\sugyeong_github\\\\FingerVein-Spoofing\\\\model\\\\result')\n",
    "\n",
    "    # make data, (sample, channel, length)\n",
    "    save_path=\"D:\\\\study\\\\sugyeong_github\\\\FingerVein-Spoofing\\\\\"\n",
    "\n",
    "    print('>> train')\n",
    "    with open(save_path+\"train.pickle\", mode='rb') as f:\n",
    "        trainDict = pickle.load(f)\n",
    "\n",
    "    train_X = trainDict['freq_signal']\n",
    "    train_y = trainDict['class'].ravel()\n",
    "\n",
    "    print('>> test')\n",
    "    with open(save_path+\"test.pickle\", mode='rb') as f:\n",
    "        testDict = pickle.load(f)\n",
    "\n",
    "    test_X = testDict['freq_signal']\n",
    "    test_y = testDict['class'].ravel()\n",
    "    \n",
    "    #data shuffle\n",
    "    tmp = [[x,y] for x, y in zip(train_X,train_y)]\n",
    "    random.shuffle(tmp)\n",
    "    train_X = [n[0] for n in tmp]\n",
    "    train_y = [n[1] for n in tmp]\n",
    "\n",
    "    train_y=np.array(train_y)\n",
    "    \n",
    "    #data전처리\n",
    "    train_X=np.reshape(train_X, ( 580,1,750))\n",
    "    test_X=np.reshape(test_X, ( 562,1,750)) \n",
    "    \n",
    "    train_X = train_X / 255.0\n",
    "    test_X = test_X / 255.0\n",
    "    \n",
    "    t=torch.tensor(train_y)\n",
    "    t=t.long()\n",
    "    train_y=F.one_hot(t,num_classes=2)\n",
    "    \n",
    "    t=torch.tensor(test_y.squeeze())\n",
    "    t=t.long()\n",
    "    test_y=F.one_hot(t,num_classes=2)\n",
    "                                        \n",
    "    X_train, X_test, Y_train, Y_test = train_X,test_X,train_y,test_y\n",
    "\n",
    "    base_filters = 32\n",
    "    filter_list=[16,32,32,64,128,256,256]\n",
    "    m_blocks_list=[2,2,2,3,3,4,4]\n",
    "\n",
    "    run_exp(\n",
    "        base_filters=base_filters,\n",
    "        filter_list=filter_list,\n",
    "        m_blocks_list=m_blocks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) <class 'torch.Tensor'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([0,1,0,1])\n",
    "print(print(x[0],type(x[0])))\n",
    "#F.one_hot(train_y.squeeze(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "t=torch.tensor(train_y.squeeze())\n",
    "t=t.long()\n",
    "print(t[0],type(t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        ...,\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(t,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
